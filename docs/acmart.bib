@inproceedings{
joachims2018deep,
title={Deep Learning with Logged Bandit Feedback},
author={Thorsten Joachims and Adith Swaminathan and Maarten de Rijke},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJaP_-xAb},
}

@article{dudik,
  author    = {Miroslav Dud{\'{\i}}k and
               John Langford and
               Lihong Li},
  title     = {Doubly Robust Policy Evaluation and Learning},
  journal   = {CoRR},
  volume    = {abs/1103.4601},
  year      = {2011},
  url       = {http://arxiv.org/abs/1103.4601},
  archivePrefix = {arXiv},
  eprint    = {1103.4601},
  timestamp = {Mon, 13 Aug 2018 16:47:20 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1103-4601.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{deepq,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  archivePrefix = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{overparameterize1,
  author    = {David Brandfonbrener and
               William F. Whitney and
               Rajesh Ranganath and
               Joan Bruna},
  title     = {Overfitting and Optimization in Offline Policy Learning},
  journal   = {CoRR},
  volume    = {abs/2006.15368},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.15368},
  archivePrefix = {arXiv},
  eprint    = {2006.15368},
  timestamp = {Wed, 01 Jul 2020 15:21:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-15368.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kang_schafer,
author = {Joseph D. Y. Kang and Joseph L. Schafer},
title = {{Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a Population Mean from Incomplete Data}},
volume = {22},
journal = {Statistical Science},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {523 -- 539},
keywords = {Causal inference, missing data, model-assisted survey estimation, propensity score, weighted estimating equations},
year = {2007},
doi = {10.1214/07-STS227},
URL = {https://doi.org/10.1214/07-STS227}
}

@article{jiang,
  author    = {Nan Jiang and
               Lihong Li},
  title     = {Doubly Robust Off-policy Evaluation for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.03722},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.03722},
  archivePrefix = {arXiv},
  eprint    = {1511.03722},
  timestamp = {Mon, 13 Aug 2018 16:46:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JiangL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{poem,
  author    = {Adith Swaminathan and
               Thorsten Joachims},
  title     = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
  journal   = {CoRR},
  volume    = {abs/1502.02362},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.02362},
  archivePrefix = {arXiv},
  eprint    = {1502.02362},
  timestamp = {Mon, 13 Aug 2018 16:47:12 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SwaminathanJ15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{offset_tree,
  author    = {Alina Beygelzimer and
               John Langford},
  title     = {The Offset Tree for Learning with Partial Labels},
  journal   = {CoRR},
  volume    = {abs/0812.4044},
  year      = {2008},
  url       = {http://arxiv.org/abs/0812.4044},
  archivePrefix = {arXiv},
  eprint    = {0812.4044},
  timestamp = {Mon, 13 Aug 2018 16:48:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-0812-4044.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{Watkins92q-learning,
    author = {Christopher J. C. H. Watkins and Peter Dayan},
    title = {Q-learning},
    booktitle = {Machine Learning},
    year = {1992},
    pages = {279--292}
}


@InProceedings{pmlr-v97-vlassis19a,
  title = 	 {On the Design of Estimators for Bandit Off-Policy Evaluation},
  author =       {Vlassis, Nikos and Bibaut, Aurelien and Dimakopoulou, Maria and Jebara, Tony},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6468--6476},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/vlassis19a/vlassis19a.pdf},
  url = 	 {
http://proceedings.mlr.press/v97/vlassis19a.html
},
  abstract = 	 {Off-policy evaluation is the problem of estimating the value of a target policy using data collected under a different policy. Given a base estimator for bandit off-policy evaluation and a parametrized class of control variates, we address the problem of computing a control variate in that class that reduces the risk of the base estimator. We derive the population risk as a function of the class parameters and we establish conditions that guarantee risk improvement. We present our main results in the context of multi-armed bandits, and we propose a simple design for contextual bandits that gives rise to an estimator that is shown to perform well in multi-class cost-sensitive classification datasets.}
}

